{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7fd651-0401-4f71-b87e-06a8f1fbe309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from logging_file import *\n",
    "from utils.plot_utils import *\n",
    "from utils.data_manipulation import *\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306eec7b-4bcb-4838-b3ef-aa8ea4204ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(zip_path, extract_to):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def make_data_folder(zip_dir='zipped_data/labelized/', data_dir='data/labelized/'):\n",
    "    images_dir = os.path.join(data_dir, \"images\")\n",
    "    annotations_dir = os.path.join(data_dir, \"annotations\")\n",
    "\n",
    "    if os.path.exists(data_dir):\n",
    "        shutil.rmtree(data_dir)\n",
    "    os.makedirs(data_dir)\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(annotations_dir, exist_ok=True)\n",
    "\n",
    "    zip_files = [f for f in os.listdir(zip_dir) if f.endswith(\".zip\")]\n",
    "    \n",
    "    for zip_file in tqdm(zip_files, desc='Extracting zip files'):\n",
    "        zip_path = os.path.join(zip_dir, zip_file)\n",
    "        extract_to = os.path.join(zip_dir, \"tmp\")\n",
    "        \n",
    "        extract_zip(zip_path, extract_to)\n",
    "        \n",
    "        intermediate_folders = os.listdir(extract_to)\n",
    "        if len(intermediate_folders) != 1:\n",
    "            continue \n",
    "        intermediate_folder = os.path.join(extract_to, intermediate_folders[0])\n",
    "        \n",
    "        for class_dir in os.listdir(intermediate_folder):\n",
    "            class_path = os.path.join(intermediate_folder, class_dir)\n",
    "            \n",
    "            if os.path.isdir(class_path):  \n",
    "                for file in os.listdir(class_path):\n",
    "                    file_path = os.path.join(class_path, file)\n",
    "                    \n",
    "                    if file.endswith((\".jpg\")):\n",
    "                        shutil.move(file_path, os.path.join(images_dir, file))\n",
    "                    \n",
    "                    elif file.endswith(\".txt\"):\n",
    "                        shutil.move(file_path, os.path.join(annotations_dir, file))\n",
    "        \n",
    "        shutil.rmtree(extract_to)\n",
    "\n",
    "def clean_unmatched_files(image_folder='data/labelized/images/', \n",
    "                          annotation_folder='data/labelized/annotations/', \n",
    "                          backup_folder=\"backup_invalid_files\"):\n",
    "    \n",
    "    logger = init_preprocess_logger()\n",
    "    os.makedirs(backup_folder, exist_ok=True)\n",
    "\n",
    "    image_files = set(f.replace('.jpg', '') for f in os.listdir(image_folder) if f.endswith('.jpg'))\n",
    "    annotation_files = set(f.replace('.txt', '') for f in os.listdir(annotation_folder) if f.endswith('.txt'))\n",
    "\n",
    "    images_to_delete = image_files - annotation_files\n",
    "    annotations_to_delete = annotation_files - image_files\n",
    "\n",
    "    for img in images_to_delete:\n",
    "        img_path = os.path.join(image_folder, img + '.jpg')\n",
    "        try:\n",
    "            shutil.move(img_path, os.path.join(backup_folder, os.path.basename(img_path)))\n",
    "            logger.info(f\"Moved unmatched image {img_path} to backup folder.\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"File not found error: {img_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error moving {img_path}: {e}\")\n",
    "\n",
    "    for txt in annotations_to_delete:\n",
    "        txt_path = os.path.join(annotation_folder, txt + '.txt')\n",
    "        try:\n",
    "            shutil.move(txt_path, os.path.join(backup_folder, os.path.basename(txt_path)))\n",
    "            logger.info(f\"Moved unmatched annotation {txt_path} to backup folder.\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"File not found error: {txt_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error moving {txt_path}: {e}\")\n",
    "\n",
    "    print(\"Cleaning completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4293f41e-208e-4bd6-a60c-a0db8b5880cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_similar_images(image_folder='data/labelized/images/', \n",
    "                         backup_folder=\"backup_invalid_files\", \n",
    "                         similarity_threshold=0.8):\n",
    "    logger = init_preprocess_logger()\n",
    "    \n",
    "    os.makedirs(backup_folder, exist_ok=True)\n",
    "\n",
    "    images = sorted([os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(\".jpg\")])\n",
    "    groups = [] \n",
    "    current_group = [images[0]]\n",
    "\n",
    "    moved_images = set()\n",
    "\n",
    "    for i in tqdm(range(1, len(images)), desc=\"Grouping similar images\"):\n",
    "        try:\n",
    "            if images[i-1] in moved_images or images[i] in moved_images:\n",
    "                continue\n",
    "\n",
    "            score = compare_images(images[i-1], images[i], logger, backup_folder, moved_images)\n",
    "\n",
    "            if score is None:\n",
    "                continue\n",
    "            \n",
    "            if score >= similarity_threshold:\n",
    "                current_group.append(images[i])\n",
    "            else:\n",
    "                groups.append(current_group)\n",
    "                current_group = [images[i]]\n",
    "        \n",
    "        except Exception as e:\n",
    "            move_image_and_annotation(images[i], logger)\n",
    "            moved_images.add(images[i])  \n",
    "            continue  \n",
    "\n",
    "    groups.append(current_group) \n",
    "\n",
    "    with open('pickle_files/data/groups.pkl', 'wb') as file:\n",
    "        pickle.dump(groups, file)\n",
    "\n",
    "    return groups\n",
    "\n",
    "def compare_images(img_path1, img_path2, logger, backup_folder, moved_images):\n",
    "    try:\n",
    "        img1 = cv2.imread(img_path1)\n",
    "        img2 = cv2.imread(img_path2)\n",
    "\n",
    "        if img1 is None:\n",
    "            move_image_and_annotation(img1, logger)\n",
    "            moved_images.add(img_path1)\n",
    "            return None\n",
    "\n",
    "        if img2 is None:\n",
    "            move_image_and_annotation(img2, logger)\n",
    "            moved_images.add(img_path2)\n",
    "            return None\n",
    "\n",
    "        if img1.size != img2.size:\n",
    "            return 0\n",
    "\n",
    "        img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "        img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        score = ssim(img1_gray, img2_gray)\n",
    "        return score\n",
    "\n",
    "    except Exception as e:\n",
    "        move_image_and_annotation(img1, logger)\n",
    "        move_image_and_annotation(img2, logger)\n",
    "        moved_images.add(img_path1)\n",
    "        moved_images.add(img_path2)\n",
    "        return None\n",
    "\n",
    "def calculate_surface(bounding_box):\n",
    "    _, _, _, width, height = bounding_box\n",
    "    return width * height\n",
    "\n",
    "def parse_annotation_file(annotation_path):\n",
    "    bounding_boxes = []\n",
    "    with open(annotation_path, 'r') as file:\n",
    "        for line in file:\n",
    "            bounding_boxes.append(list(map(float, line.split())))\n",
    "    return bounding_boxes\n",
    "\n",
    "def keep_best_images(groups):\n",
    "    best_images = []\n",
    "    \n",
    "    for group in tqdm(groups, desc=\"Keeping best images\"):\n",
    "        best_annotation = None\n",
    "        max_surface = -1\n",
    "        \n",
    "        for image_path in group:\n",
    "            annotation_path = image_path.replace('images', 'annotations').replace('.jpg', '.txt')\n",
    "            \n",
    "            bounding_boxes = parse_annotation_file(annotation_path)\n",
    "            \n",
    "            if len(bounding_boxes) > 1:\n",
    "                best_images.append(annotation_path)\n",
    "                continue\n",
    "            \n",
    "            total_surface = calculate_surface(bounding_boxes[0])\n",
    "            \n",
    "            if total_surface > max_surface:\n",
    "                max_surface = total_surface\n",
    "                best_annotation = annotation_path\n",
    "        \n",
    "        if best_annotation:\n",
    "            best_images.append(convert_path(best_annotation, mode='txt2img'))\n",
    "\n",
    "    with open('pickle_files/data/best_images.pkl', 'wb') as file:\n",
    "        pickle.dump(best_images, file)  \n",
    "\n",
    "    print(\"Only the best images have been kept\")\n",
    "    return best_images\n",
    "\n",
    "def move_non_best_files(groups, best_images, backup_folder=\"backup_invalid_files\"):\n",
    "    os.makedirs(backup_folder, exist_ok=True) \n",
    "    logger = init_preprocess_logger()\n",
    "    \n",
    "    best_images_set = set(best_images)  \n",
    "    \n",
    "    for group in tqdm(groups, desc=\"Moving non best files\"):\n",
    "        for image_path in group:\n",
    "            annotation_path = image_path.replace('images', 'annotations').replace('.jpg', '.txt')\n",
    "            \n",
    "            if image_path not in best_images_set:\n",
    "                try:\n",
    "                    backup_image_path = os.path.join(backup_folder, os.path.basename(image_path))\n",
    "                    shutil.move(image_path, backup_image_path)\n",
    "                    logger.info(f\"Moved image {os.path.basename(image_path)} to backup folder.\")\n",
    "\n",
    "                    if os.path.exists(annotation_path):\n",
    "                        backup_annotation_path = os.path.join(backup_folder, os.path.basename(annotation_path))\n",
    "                        shutil.move(annotation_path, backup_annotation_path)\n",
    "                        logger.info(f\"Moved annotation {os.path.basename(annotation_path)} to backup folder\")\n",
    "                except FileNotFoundError as e:\n",
    "                    logger.error(f\"File not found error: {os.path.basename(image_path)}\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Erreur moving {os.path.basename(image_path)}\")\n",
    "\n",
    "\n",
    "    print(\"All files have been moved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6687efc-8e14-4f36-a7c7-3079f90833ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting zip files: 100%|██████████████████████████████████████████████████████████████| 4/4 [00:30<00:00,  7.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grouping similar images: 100%|█████████████████████████████████████████████████████| 9857/9857 [39:43<00:00,  4.14it/s]\n",
      "Keeping best images: 100%|████████████████████████████████████████████████████████| 4886/4886 [00:46<00:00, 105.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only the best images have been kept\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving non best files: 100%|██████████████████████████████████████████████████████| 4886/4886 [00:06<00:00, 740.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been moved\n",
      "Data preparation is complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "make_data_folder()\n",
    "clean_unmatched_files()\n",
    "groups = group_similar_images()\n",
    "best_images = keep_best_images(groups)\n",
    "move_non_best_files(groups, best_images)\n",
    "print(\"Data preparation is complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a823ca9-cf33-47d4-b103-5115e458ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coun"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
